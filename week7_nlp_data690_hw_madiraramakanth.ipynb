{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jYXS2gJA_kx",
        "outputId": "f147e01a-1bcc-45d0-e696-346d848a6b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "pip install textblob nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "file_path = \"/content/Burbank.txt\"\n",
        "with open(file_path, 'r') as file:\n",
        "    burbank_text = file.read()\n",
        "blob = TextBlob(burbank_text)\n",
        "polarity = blob.sentiment.polarity\n",
        "print(\"Text Polarity:\", polarity)\n",
        "print(\"Probability of Negative Sentiment:\", negative_probability)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDtiIeVEBYk5",
        "outputId": "fb0700d0-5686-4156-8c6e-8d81a3fa0d16"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Polarity: 0.09869334480780263\n",
            "Probability of Negative Sentiment: 0.45065332759609866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "print(\"Overall Sentiment (Polarity):\", polarity)\n",
        "print(\"Overall Subjectivity:\", subjectivity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVmDayB3BrqP",
        "outputId": "8aa4defc-104b-4e53-c91d-dc5062d12e13"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Sentiment (Polarity): 0.09869334480780263\n",
            "Overall Subjectivity: 0.3790877796901893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "topics = [Word(word).singularize().lemmatize() for word in blob.words]\n",
        "unique_topics = set(topics)\n",
        "print(\"Key Topics:\", unique_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KrVD8S-DNaC",
        "outputId": "4970895d-acb0-4095-cebd-031ff7b8c387"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Topics: {'path', 'who', 'doing', 'group', 'have', 'putting', 'State', 'head', 'higher', 'added', 'con', 'task', 'Kevin', 'Ramirez', 'each', 'Fernando', 'Next', 'Andre', 'current', 'conduct', 'later', 'relief', 'After', '6:30', 'solve', 'supplying', 'vice', 'little', 'reviewed', 'Karpe', 'Radar', 'Way', 'out', 'agreement', 'immediately', 'did', 'Van', 'study', 'system', 'share', 'airport–basically', 'Californium', 'depending', 'cause', 'FAA', 'became', 'extreme', 'which', 'country', 'implemented', 'implementing', 'found', 'reaching', 'rather', 'recommended', 'discus', 'senior', 'Feb', 'earlier', 'Suzanne', 'meet', 'cheer', 'when', 'news', 'You', 'conducted', 'argue', 'example', 'many', 'change', 'TRACON', 'helpful', 'difficult', 'Wednesday', 'climb', 'Fulton', 'community', 'often', 'at', '2007', 'navigation', 'piece', 'shift', 'term', 'air', 'done', 'Held', 'person', 'UproarLA', 'well', 'operating', 'here', 'worked', 'transportation', 'such', '19', 'dispersing', 'While', 'Administration', 'make', 'affected', 'Inc', 'proposed', 'how', 'return', 'there', 'intently', 'flight', 'demonstrated', 'possible', 'throughout', 'start', 'Community', 'after', 'some', '1', 'message', 'suffer', 'center', 'Since', 'sooner', 'that', 'Burbank', 'hi', 'sector', 'attention', 'it', 'sixth', 'direct', 'regulation', 'Approach', 'Village', 'glad', 'Federal', 'Member', 'Scholten', 'representing', 'combining', 'from', 'issue', 'everybody', '2020', 'departing', 'environmental', 'Some', 'Potential', 'those', 'by', 'should', 'were', 'say', 'way', 'addres', 'FFA', 'stayed', 'consulting', 'thing', 'available', 'San', 'what', 'deliberate', 'handling', 'Vector', 'April', 'blame', 'A', 'changing', 'manage', 'newcomer', 'just', 'airport', 'included', 'paying', 'until', 'dispersed', 'board', 'implement', 'ascending', 'destination', 'work', 'achieve', 'resident', 'alway', 'used', 'control', 'very', 'Control', 'jet', 'stated', 'next', 'geared', 'condition', '2', 'NextGen', 'So', 'problem', 'I', 'senators…', 'both', 'Airplane', 'a', 'six', 'with', 'Sherman', 'le', 'pilot', 'action', '“', 'created', 'far', 'south', 'no', 'Diego', 'Several', 'Noise', 'result', 'review', 'historic', 'showed', 'resulted', 'ye', 'City', 'concentrated', 'toward', 'Beth', 'another', 'Homeowner', 'representative', 'in', 'clapping', 'limitation', 'presented', 'making', 'every', 'sat', 'navigational', 'congressional', 'ha', 'over', 'Task', 'safer', 'Neighborhood', 'month', 'west', 'They', 'all', 'quicker', 'could', 'complex', 'firm', 'isn', 'LLC', 'stone-like', 'consider', 'll', 'contributing', 'complained', 'Terminal', 'narrow', 'Quiet', 'waypoint', 'moved', 'We', 'Diverse', 'go', '101', 'one', 'pressure', 'district', 'procedure', 'try', 'use', 'than', 'plane', 'System', 'and/or', 'own', 'continued', 'Part', 'Valley', 'controller', 'my', 'guide', 'North', 'Springer', 'had', 'variou', 'something', 'Hollywood', 'several', 'force', 'forward', 'N', 'past', 'about', 'located', 'happened', 'Pacoima', 't', 'facility', 'ascent', 'lengthy', 'happen', 'an', 'increased', 'refresh', 'landing', 'workload', 'hearing', 'When', 'be', 'satellite-based', 'according', 'audience', 'program', 'efficient', 'taken', 'because', 'expert', 'get', 'outcome', 'air-traffic', 'Nuy', 'take', 'detailed', 'returned', 'm', 'In', 'them', 'under', 'aviation', 'Many', 'load', 'noise', 'but', '\\ufeffAirport', 'acros', 'Congres', 'airline', 'Beautiful', 'route', 'bulk', '—', 'It', 'they', 'too', 'distilling', 'increase', 'Consulting', 'director', 'Studio', 'region', 'same', 'and', 'rate', 'Lewi', 'Encino', 'Sky', 'wa', 'turn', 'charge', 'listened', 'However', 'is', 'pro', 'takeoff', 'combine', 'made', 'for', 'collective', 'can', 'face', 'on', 'confirmed', 'Southern', 'erupted', 'other', 'Association', 'United', 'neighborhood', 'passive', 'Oak', 'may', 'president', 'altitude', 'not', 'wider', 'single', 'Lo', 'steeper', 'we', 'explanation', 'recommendation', 'implementation', 'north', 'ignore', 'final', 'fuel', 'range', '’', 'affecting', 'feasibility', '”', 'standard', 'fair', 'East', 'presentation', 'best', 'farther', 'member', 'ongoing', 's', 'two', 'regulate', 'proposal', 'practice', 'research', 'slightly', 'so', 'northbound', 'among', 'close', 'thi', 'disqualified', 'analyzed', 'surrounding', 'reconvene', 'above', 'area', 'submitted', 'drifted', 'service', 'public', 'Valley–including', 'facilitator', 'listen', 'before', 'quickly', 'safe', 'of', 'local', 'abate', 'more', 'historical', 'Transportation', 'need', 'would', 'Even', 'brought', 'consultant', 'established', 'to', 'tried', 'whether', 'are', 'meeting', 'criterium', 'number', 'airfield', 'efficiently', 'listening', 'around', '2017', 'Meeting', 'Air', 'attendance', 'resource', 'HMMH', 'minimum', 'overhead', 'Angele', 'displayed', 'Mayor', 'airspace', 'will', 'create', 'having', 'Force', 'ascend', 'p.m', 'said', 'request', 'figure', 'solution', 'if', 'develop', 'Marriott', 'gave', 'concentrating', 'spent', 'long', 'traffic', 'Council', 'night', 'The', 'really', 'safety', 'southern', 'Generation', 'most', 'claiming', 'He', 'or', '2500', 'Sharon', 'mandatory', 'airliner', 'quieter', 'know', 'Adam', 'Reindel', 'aircraft', 'also', 'That', 'Airport', 'majority', 'March', 'organization', 'Aviation', 'once', 'nuisance', 'analyze', 'Sixth', 'been', 'off', 'their', 'held', 'flying', 'stick', 'training', 'Gene', 'the', 'fewer', 'weather', 'Senator', 'frustrated', 'congressman', 'suggested', 'recommend', 'five', 'report', 'Freeway'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC  # Changed to SVC for simplicity\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "df_a = pd.read_csv('/content/amazon_cells_labelled.txt', sep='\\t', header=None, names=['review', 'label'])\n",
        "df_i = pd.read_csv('/content/imdb_labelled.txt', sep='\\t', header=None, names=['review', 'label'])\n",
        "df_y = pd.read_csv('/content/yelp_labelled.txt', sep='\\t', header=None, names=['review', 'label'])\n",
        "df_a['company'] = 'Amazon'\n",
        "df_i['company'] = 'IMDb'\n",
        "df_y['company'] = 'Yelp'\n",
        "data = pd.concat([df_a, df_i, df_y])\n",
        "data.to_csv('sentiment_data.csv', index=False)\n",
        "print(data.head())\n",
        "print(\"Columns:\", data.columns)\n",
        "print(\"Null Values:\", data.isnull().sum())\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def tokenize(text):\n",
        "    return [token.lemma_.lower() for token in nlp(text)\n",
        "            if token.text not in STOP_WORDS and token.text not in string.punctuation]\n",
        "class Cleaner(TransformerMixin):\n",
        "    def transform(self, X, **params):\n",
        "        return [tokenize(text) for text in X]\n",
        "    def fit(self, X, y=None, **params):\n",
        "        return self\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "pipeline = Pipeline([\n",
        "    ('cleaner', Cleaner()),\n",
        "    ('vectorizer', TfidfVectorizer(tokenizer=lambda txt: txt, lowercase=False)),\n",
        "    ('classifier', SVC(kernel='linear'))\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "preds = pipeline.predict(X_test)\n",
        "\n",
        "for sample, pred in zip(X_test.head(), preds):\n",
        "    print(sample, \"Prediction ➔\", 'Positive' if pred == 1 else 'Negative')\n",
        "\n",
        "print(\"Accuracy on Training Set:\", pipeline.score(X_train, y_train))\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxyL1pF2HbXq",
        "outputId": "8bf8c472-086b-4778-d9a2-c2e89494e8e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  label company\n",
            "0  So there is no way for me to plug it in here i...      0  Amazon\n",
            "1                        Good case, Excellent value.      1  Amazon\n",
            "2                             Great for the jawbone.      1  Amazon\n",
            "3  Tied to charger for conversations lasting more...      0  Amazon\n",
            "4                                  The mic is great.      1  Amazon\n",
            "Columns: Index(['review', 'label', 'company'], dtype='object')\n",
            "Null Values: review     0\n",
            "label      0\n",
            "company    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's close to my house, it's low-key, non-fancy, affordable prices, good food. Prediction ➔ Positive\n",
            "If you stay in Vegas you must get breakfast here at least once. Prediction ➔ Positive\n",
            "Let's start with all the problemsthe acting, especially from the lead professor, was very, very bad.   Prediction ➔ Negative\n",
            "It's too bad that everyone else involved didn't share Crowe's level of dedication to quality, for if they did, we'd have a far better film on our hands than this sub-par mess.   Prediction ➔ Negative\n",
            "i felt insulted and disrespected, how could you talk and judge another human being like that? Prediction ➔ Negative\n",
            "Accuracy on Training Set: 0.9545040946314831\n",
            "Accuracy on Test Set: 0.8145454545454546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6ACWtjZJeBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}